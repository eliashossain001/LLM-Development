{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcdea72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de2ce6e6",
   "metadata": {},
   "source": [
    "### Implementing GPT Model from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f0a893",
   "metadata": {},
   "source": [
    "The smallest GPT-2 model (117 million parameters) has 12 attention heads and a context vector embedding size of 768. The largest GPT-2 model (1.5 billion parameters) has 25 attention heads and a context vector embedding size of 1600. Note that the embedding sizes of the token inputs and context embeddings are the same in GPT models (d_in = d_out)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3de9e04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_SETTINGS_124M = {\n",
    "    \"token_count\": 50257,   # Vocabulary size\n",
    "    \"seq_length\": 1024,     # Context length\n",
    "    \"embed_size\": 768,      # Embedding dimension\n",
    "    \"attn_heads\": 12,       # Number of attention heads\n",
    "    \"num_layers\": 12,       # Number of layers\n",
    "    \"dropout_prob\": 0.1,    # Dropout rate\n",
    "    \"use_qkv_bias\": False   # Query-Key-Value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bda6d7",
   "metadata": {},
   "source": [
    "### DUMMY GPT MODEL CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bcb7ead8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class MockGPTModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.token_embed = nn.Embedding(config[\"token_count\"], config[\"embed_size\"])\n",
    "        self.position_embed = nn.Embedding(config[\"seq_length\"], config[\"embed_size\"])\n",
    "        self.embed_dropout = nn.Dropout(config[\"dropout_prob\"])\n",
    "        \n",
    "        # Placeholder for Transformer Block\n",
    "        self.transformer_layers = nn.Sequential(\n",
    "            *[MockTransformerLayer(config) for _ in range(config[\"num_layers\"])]\n",
    "        )\n",
    "        \n",
    "        # Placeholder for LayerNorm\n",
    "        self.norm_layer = MockLayerNorm(config[\"embed_size\"])\n",
    "        self.output_layer = nn.Linear(\n",
    "            config[\"embed_size\"], config[\"token_count\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, input_idx):\n",
    "        batch_size, seq_len = input_idx.shape\n",
    "        token_embeddings = self.token_embed(input_idx)\n",
    "        position_embeddings = self.position_embed(torch.arange(seq_len, device=input_idx.device))\n",
    "        x = token_embeddings + position_embeddings\n",
    "        x = self.embed_dropout(x)\n",
    "        x = self.transformer_layers(x)\n",
    "        x = self.norm_layer(x)\n",
    "        logits = self.output_layer(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class MockTransformerLayer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        # Placeholder implementation\n",
    "\n",
    "    def forward(self, x):\n",
    "        # This block does nothing and just returns its input.\n",
    "        return x\n",
    "\n",
    "\n",
    "class MockLayerNorm(nn.Module):\n",
    "    def __init__(self, norm_shape, epsilon=1e-5):\n",
    "        super().__init__()\n",
    "        # Placeholder for LayerNorm interface\n",
    "\n",
    "    def forward(self, x):\n",
    "        # This layer does nothing and just returns its input.\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53994900",
   "metadata": {},
   "source": [
    "Let's prepare the input data and initialize the new GPT model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a6add5",
   "metadata": {},
   "source": [
    "### Step 1: Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "caf4a125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "import torch\n",
    "\n",
    "# Initialize tokenizer\n",
    "text_encoder = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "# Create a list for storing tokenized sequences\n",
    "token_batches = []\n",
    "\n",
    "sentence_1 = \"Every effort moves you\"\n",
    "sentence_2 = \"Every day holds a\"\n",
    "\n",
    "# Tokenizing and appending to the batch\n",
    "token_batches.append(torch.tensor(text_encoder.encode(sentence_1)))\n",
    "token_batches.append(torch.tensor(text_encoder.encode(sentence_2)))\n",
    "\n",
    "# Stack tensors along dimension 0\n",
    "token_batches = torch.stack(token_batches, dim=0)\n",
    "\n",
    "# Print the tokenized batch\n",
    "print(token_batches)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff42b9f1",
   "metadata": {},
   "source": [
    "### Create an Instance of Dummy GPT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "228125cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[-0.9289,  0.2748, -0.7557,  ..., -1.6070,  0.2702, -0.5888],\n",
      "         [-0.4476,  0.1726,  0.5354,  ..., -0.3932,  1.5285,  0.8557],\n",
      "         [ 0.5680,  1.6053, -0.2155,  ...,  1.1624,  0.1380,  0.7425],\n",
      "         [ 0.0447,  2.4787, -0.8843,  ...,  1.3219, -0.0864, -0.5856]],\n",
      "\n",
      "        [[-1.5474, -0.0542, -1.0571,  ..., -1.8061, -0.4494, -0.6747],\n",
      "         [-0.8422,  0.8243, -0.1098,  ..., -0.1434,  0.2079,  1.2046],\n",
      "         [ 0.1355,  1.1858, -0.1453,  ...,  0.0869, -0.1590,  0.1552],\n",
      "         [ 0.1666, -0.8138,  0.2307,  ...,  2.5035, -0.3055, -0.3083]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "mock_model = MockGPTModel(LLM_SETTINGS_124M)\n",
    "output_logits = mock_model(token_batches)\n",
    "\n",
    "print(\"Output shape:\", output_logits.shape)\n",
    "print(output_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c01d12",
   "metadata": {},
   "source": [
    "### GPT ARCHITECTURE PART 2: LAYER NORMALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f7074611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
      "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "# Create a random input tensor\n",
    "sample_input = torch.randn(2, 5)  # A\n",
    "\n",
    "# Define a simple neural network layer\n",
    "neural_layer = nn.Sequential(nn.Linear(5, 6), nn.ReLU())\n",
    "\n",
    "# Pass the input through the layer\n",
    "output_result = neural_layer(sample_input)\n",
    "\n",
    "# Print the output\n",
    "print(output_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc7ba0f",
   "metadata": {},
   "source": [
    "Before implementing the layer normalization, we shall apply the mean variance of the output vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4aed1522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[0.1324],\n",
      "        [0.2170]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[0.0231],\n",
      "        [0.0398]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Compute mean along the last dimension\n",
    "output_mean = output_result.mean(dim=-1, keepdim=True)\n",
    "\n",
    "# Compute variance along the last dimension\n",
    "output_variance = output_result.var(dim=-1, keepdim=True)\n",
    "\n",
    "# Print mean and variance\n",
    "print(\"Mean:\\n\", output_mean)\n",
    "print(\"Variance:\\n\", output_variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d168989",
   "metadata": {},
   "source": [
    "Next, let us apply layer normalization to the layer outputs we obtained earlier. The operation consists of subtracting the mean and dividing by the square root of the variance (also known as standard deviation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e0b94c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized layer outputs:\n",
      " tensor([[ 0.6159,  1.4126, -0.8719,  0.5872, -0.8719, -0.8719],\n",
      "        [-0.0189,  0.1121, -1.0876,  1.5173,  0.5647, -1.0876]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "Mean:\n",
      " tensor([[    0.0000],\n",
      "        [    0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Normalize the output\n",
    "normalized_output = (output_result - output_mean) / torch.sqrt(output_variance)\n",
    "\n",
    "# Compute mean and variance of the normalized output\n",
    "normalized_mean = normalized_output.mean(dim=-1, keepdim=True)\n",
    "normalized_variance = normalized_output.var(dim=-1, keepdim=True)\n",
    "\n",
    "# Print results\n",
    "print(\"Normalized layer outputs:\\n\", normalized_output)\n",
    "print(\"Mean:\\n\", normalized_mean)\n",
    "print(\"Variance:\\n\", normalized_variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fafcfbd",
   "metadata": {},
   "source": [
    "To improve readability, we can also turn off the scientific notation when printing tensor values by setting sci_mode to False:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1eec1925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[    0.0000],\n",
      "        [    0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Set print options to disable scientific notation\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "\n",
    "# Print mean and variance\n",
    "print(\"Mean:\\n\", normalized_mean)\n",
    "print(\"Variance:\\n\", normalized_variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09e95e8",
   "metadata": {},
   "source": [
    "Let's now encapsulate this process in a PyTorch module that we can use in the GPT model later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0ab56494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class NormLayer(nn.Module):\n",
    "    def __init__(self, embed_size):\n",
    "        super().__init__()\n",
    "        self.epsilon = 1e-5\n",
    "        self.gain = nn.Parameter(torch.ones(embed_size))\n",
    "        self.bias = nn.Parameter(torch.zeros(embed_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_val = x.mean(dim=-1, keepdim=True)\n",
    "        variance_val = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        normalized_x = (x - mean_val) / torch.sqrt(variance_val + self.epsilon)\n",
    "        return self.gain * normalized_x + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2075212",
   "metadata": {},
   "source": [
    "This specific implementation of layer Normalization operates on the last dimension of the input tensor x, which represents the embedding dimension (emb_dim).\n",
    "\n",
    "The variable epsilon added to the variance to prevent division by zero during normalization.\n",
    "\n",
    "The scale and shift are two trainable parameters (of the same dimension as the input) that the LLM automatically adjusts during training if it is determined that doing so would improve the model's performance on its training task.\n",
    "\n",
    "This allows the model to learn appropriate scaling and shifting that best suit the data it is processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f4332482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[    -0.0000],\n",
      "        [     0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the normalization layer\n",
    "norm_layer = NormLayer(embed_size=5)\n",
    "\n",
    "# Apply layer normalization\n",
    "normalized_output = norm_layer(sample_input)\n",
    "\n",
    "# Compute mean and variance of the normalized output\n",
    "normalized_mean = normalized_output.mean(dim=-1, keepdim=True)\n",
    "normalized_variance = normalized_output.var(dim=-1, unbiased=False, keepdim=True)\n",
    "\n",
    "# Print results\n",
    "print(\"Mean:\\n\", normalized_mean)\n",
    "print(\"Variance:\\n\", normalized_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d8473a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f24da50",
   "metadata": {},
   "source": [
    "### GPT ARCHITECTURE PART 3: FEEDFORWARD NEURAL NETWORK WITH GELU ACTIVATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "da7d9f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        return 0.5 * input_tensor * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n",
    "            (input_tensor + 0.044715 * torch.pow(input_tensor, 3))\n",
    "        ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0435c989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Initialize activation functions\n",
    "gelu_activation, relu_activation = GELU(), nn.ReLU()\n",
    "\n",
    "# Generate sample data\n",
    "input_values = torch.linspace(-3, 3, 100)\n",
    "output_gelu, output_relu = gelu_activation(input_values), relu_activation(input_values)\n",
    "\n",
    "# Plot the activation functions\n",
    "plt.figure(figsize=(8, 3))\n",
    "for i, (output, act_name) in enumerate(zip([output_gelu, output_relu], [\"GELU\", \"ReLU\"]), 1):\n",
    "    plt.subplot(1, 2, i)\n",
    "    plt.plot(input_values, output)\n",
    "    plt.title(f\"{act_name} Activation Function\")\n",
    "    plt.xlabel(\"Input (x)\")\n",
    "    plt.ylabel(f\"{act_name}(x)\")\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37faa1be",
   "metadata": {},
   "source": [
    "We can see in the resulting plot, ReLU is a piecewise linear function that outputs the input directly if it is positive; otherwise, it outputs zero.\n",
    "\n",
    "GELU is a smooth, nonlinear function that approximates ReLU but with a non-zero gradient for negative values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9ce81b",
   "metadata": {},
   "source": [
    "Next, let's use the GELU function to implement the small neural network module, FeedForward, that we will be using in the LLM's transformer block later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7e79ab03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MLPBlock(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(config[\"embed_size\"], 4 * config[\"embed_size\"]),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * config[\"embed_size\"], config[\"embed_size\"]),\n",
    "        )\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        return self.network(input_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "879cbdf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "print(LLM_SETTINGS_124M[\"embed_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f54b0e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 768])\n"
     ]
    }
   ],
   "source": [
    "# Initialize the feedforward network with the configuration\n",
    "mlp_block = MLPBlock(LLM_SETTINGS_124M)\n",
    "\n",
    "# Create a random input tensor\n",
    "input_tensor = torch.rand(2, 3, 768)  # A\n",
    "\n",
    "# Pass the input through the feedforward network\n",
    "output_tensor = mlp_block(input_tensor)\n",
    "\n",
    "# Print the output shape\n",
    "print(output_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cffc431",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da17d6b2",
   "metadata": {},
   "source": [
    "### GPT ARCHITECTURE PART 4: SHORTCUT CONNECTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8daa69aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DeepMLP(nn.Module):\n",
    "    def __init__(self, layer_dims, enable_skip_connection):\n",
    "        super().__init__()\n",
    "        self.enable_skip = enable_skip_connection\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Sequential(nn.Linear(layer_dims[0], layer_dims[1]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_dims[1], layer_dims[2]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_dims[2], layer_dims[3]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_dims[3], layer_dims[4]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_dims[4], layer_dims[5]), GELU())\n",
    "        ])\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        for layer in self.layers:\n",
    "            # Compute the output of the current layer\n",
    "            layer_output = layer(input_tensor)\n",
    "            # Apply skip connection if enabled and shapes match\n",
    "            if self.enable_skip and input_tensor.shape == layer_output.shape:\n",
    "                input_tensor = input_tensor + layer_output\n",
    "            else:\n",
    "                input_tensor = layer_output\n",
    "        return input_tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd65ade",
   "metadata": {},
   "source": [
    "The code implements a deep neural network with 5 layers, each consisting of a Linear layer and a GELU activation function.\n",
    "\n",
    "In the forward pass, we iteratively pass the input through the layers and optionally add the shortcut connections if the self.use_shortcut attribute is set to True. Let's use this code to first initialize a neural network without shortcut connections. Here, each layer will be initialized such that it accepts an example with 3 input values and returns 3 output values. The last layer returns a single output value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7d0e2e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define layer dimensions\n",
    "layer_dims = [3, 3, 3, 3, 3, 1]\n",
    "\n",
    "# Create a sample input tensor\n",
    "test_input = torch.tensor([[1., 0., -1.]])\n",
    "\n",
    "# Set a manual seed for reproducibility\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# Initialize the model without skip connections\n",
    "model_no_skip = DeepMLP(layer_dims, enable_skip_connection=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040570c8",
   "metadata": {},
   "source": [
    "Next, we implement a function that computes the gradients in the the model's backward pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f49245cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_gradients(model, input_tensor):\n",
    "    # Forward pass\n",
    "    output_tensor = model(input_tensor)\n",
    "    expected_output = torch.tensor([[0.]])\n",
    "\n",
    "    # Compute loss based on the difference between predicted and expected output\n",
    "    criterion = nn.MSELoss()\n",
    "    loss_value = criterion(output_tensor, expected_output)\n",
    "    \n",
    "    # Backward pass to compute gradients\n",
    "    loss_value.backward()\n",
    "\n",
    "    for param_name, param_value in model.named_parameters():\n",
    "        if 'weight' in param_name:\n",
    "            # Print the mean absolute gradient of the weights\n",
    "            print(f\"{param_name} has a gradient mean of {param_value.grad.abs().mean().item()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f5d1f6",
   "metadata": {},
   "source": [
    "In the preceding code, we specify a loss function that computes how close the model output and a user-specified target (here, for simplicity, the value 0) are.\n",
    "\n",
    "Then, when calling loss.backward(), PyTorch computes the loss gradient for each layer in the model.\n",
    "\n",
    "We can iterate through the weight parameters via model.named_parameters().\n",
    "\n",
    "Suppose we have a 33 weight parameter matrix for a given layer.\n",
    "\n",
    "In that case, this layer will have 33 gradient values, and we print the mean absolute gradient of these 33 gradient values to obtain a single gradient value per layer to compare the gradients between layers more easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "67f55efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has a gradient mean of 0.00020173587836325169\n",
      "layers.1.0.weight has a gradient mean of 0.0001201116101583466\n",
      "layers.2.0.weight has a gradient mean of 0.0007152041653171182\n",
      "layers.3.0.weight has a gradient mean of 0.001398873864673078\n",
      "layers.4.0.weight has a gradient mean of 0.005049646366387606\n"
     ]
    }
   ],
   "source": [
    "display_gradients(model_no_skip, test_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe2d4f2",
   "metadata": {},
   "source": [
    "Lets instantiate the model with skip connections and see how it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "eee553ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has a gradient mean of 0.2216978669166565\n",
      "layers.1.0.weight has a gradient mean of 0.20694100856781006\n",
      "layers.2.0.weight has a gradient mean of 0.3289698660373688\n",
      "layers.3.0.weight has a gradient mean of 0.2665731906890869\n",
      "layers.4.0.weight has a gradient mean of 1.3258538246154785\n"
     ]
    }
   ],
   "source": [
    "# Set a manual seed for reproducibility\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# Initialize the model with skip connections enabled\n",
    "model_with_skip = DeepMLP(layer_dims, enable_skip_connection=True)\n",
    "\n",
    "# Display gradients for the model with skip connections\n",
    "display_gradients(model_with_skip, test_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d8f22c",
   "metadata": {},
   "source": [
    "### GPT ARCHITECTURE PART 5: CODING ATTENTION AND LINEAR LAYERS IN A TRANSFORMER BLOCK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2979fce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TransformerLayer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.attention = MultiHeadAttention(\n",
    "            d_in=config[\"embed_size\"],\n",
    "            d_out=config[\"embed_size\"],\n",
    "            context_length=config[\"seq_length\"],\n",
    "            num_heads=config[\"attn_heads\"], \n",
    "            dropout=config[\"dropout_prob\"],\n",
    "            qkv_bias=config[\"use_qkv_bias\"]\n",
    "        )\n",
    "        self.mlp = MLPBlock(config)\n",
    "        self.norm1 = NormLayer(config[\"embed_size\"])\n",
    "        self.norm2 = NormLayer(config[\"embed_size\"])\n",
    "        self.shortcut_dropout = nn.Dropout(config[\"dropout_prob\"])\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        # Shortcut connection for attention block\n",
    "        residual = input_tensor\n",
    "        input_tensor = self.norm1(input_tensor)\n",
    "        input_tensor = self.attention(input_tensor)  # Shape: [batch_size, num_tokens, embed_size]\n",
    "        input_tensor = self.shortcut_dropout(input_tensor)\n",
    "        input_tensor = input_tensor + residual  # Add the original input back\n",
    "\n",
    "        # Shortcut connection for feedforward block\n",
    "        residual = input_tensor\n",
    "        input_tensor = self.norm2(input_tensor)\n",
    "        input_tensor = self.mlp(input_tensor)\n",
    "        input_tensor = self.shortcut_dropout(input_tensor)\n",
    "        input_tensor = input_tensor + residual  # Add the original input back\n",
    "\n",
    "        return input_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f6ae1457",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \\\n",
    "            \"d_out must be divisible by num_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length),\n",
    "                       diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
    "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim) \n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
    "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
    "\n",
    "        # Original mask truncated to the number of tokens and converted to boolean\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        # Use the mask to fill attention scores\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "        \n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2) \n",
    "        \n",
    "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec) # optional projection\n",
    "\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7f5d2916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "# Set a manual seed for reproducibility\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# Generate a random input tensor\n",
    "input_tensor = torch.rand(2, 4, 768)  # A\n",
    "\n",
    "# Initialize the transformer layer with the modified configuration\n",
    "transformer_layer = TransformerLayer(LLM_SETTINGS_124M)\n",
    "\n",
    "# Pass the input through the transformer layer\n",
    "output_tensor = transformer_layer(input_tensor)\n",
    "\n",
    "# Print input and output shapes\n",
    "print(\"Input shape:\", input_tensor.shape)\n",
    "print(\"Output shape:\", output_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc00713",
   "metadata": {},
   "source": [
    "### GPT ARCHITECTURE PART 6: ENTIRE GPT MODEL ARCHITECTURE IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "49f83fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LLMModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.token_embed = nn.Embedding(config[\"token_count\"], config[\"embed_size\"])\n",
    "        self.position_embed = nn.Embedding(config[\"seq_length\"], config[\"embed_size\"])\n",
    "        self.embed_dropout = nn.Dropout(config[\"dropout_prob\"])\n",
    "        \n",
    "        self.transformer_layers = nn.Sequential(\n",
    "            *[TransformerLayer(config) for _ in range(config[\"num_layers\"])]\n",
    "        )\n",
    "        \n",
    "        self.final_layer_norm = NormLayer(config[\"embed_size\"])\n",
    "        self.output_layer = nn.Linear(\n",
    "            config[\"embed_size\"], config[\"token_count\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, input_indices):\n",
    "        batch_size, seq_len = input_indices.shape\n",
    "        token_embeddings = self.token_embed(input_indices)\n",
    "        position_embeddings = self.position_embed(torch.arange(seq_len, device=input_indices.device))\n",
    "        x = token_embeddings + position_embeddings  # Shape [batch_size, num_tokens, embed_size]\n",
    "        x = self.embed_dropout(x)\n",
    "        x = self.transformer_layers(x)\n",
    "        x = self.final_layer_norm(x)\n",
    "        logits = self.output_layer(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b9de7ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch:\n",
      " tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      "\n",
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[ 0.1381,  0.0077, -0.1963,  ..., -0.0222, -0.1060,  0.1717],\n",
      "         [ 0.3865, -0.8408, -0.6564,  ..., -0.5163,  0.2369, -0.3357],\n",
      "         [ 0.6989, -0.1829, -0.1631,  ...,  0.1472, -0.6504, -0.0056],\n",
      "         [-0.4290,  0.1669, -0.1258,  ...,  1.1579,  0.5303, -0.5549]],\n",
      "\n",
      "        [[ 0.1094, -0.2894, -0.1467,  ..., -0.0557,  0.2911, -0.2824],\n",
      "         [ 0.0882, -0.3552, -0.3527,  ...,  1.2930,  0.0053,  0.1898],\n",
      "         [ 0.6091,  0.4702, -0.4094,  ...,  0.7688,  0.3787, -0.1974],\n",
      "         [-0.0612, -0.0737,  0.4751,  ...,  1.2463, -0.3834,  0.0609]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Set manual seed for reproducibility\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# Initialize the LLM model with the modified configuration\n",
    "llm_model = LLMModel(LLM_SETTINGS_124M)\n",
    "\n",
    "# Pass the tokenized batch through the model\n",
    "output_logits = llm_model(token_batches)\n",
    "\n",
    "# Print input and output details\n",
    "print(\"Input batch:\\n\", token_batches)\n",
    "print(\"\\nOutput shape:\", output_logits.shape)\n",
    "print(output_logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9b1d8684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 163,009,536\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total number of parameters in the model\n",
    "total_parameters = sum(param.numel() for param in llm_model.parameters())\n",
    "\n",
    "# Print the total number of parameters with formatting\n",
    "print(f\"Total number of parameters: {total_parameters:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "467a8e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token embedding layer shape: torch.Size([50257, 768])\n",
      "Output layer shape: torch.Size([50257, 768])\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of the token embedding layer\n",
    "print(\"Token embedding layer shape:\", llm_model.token_embed.weight.shape)\n",
    "\n",
    "# Print the shape of the output layer\n",
    "print(\"Output layer shape:\", llm_model.output_layer.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "881973d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters considering weight tying: 124,412,160\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total parameters excluding the output layer (weight tying consideration)\n",
    "total_params_excluding_output = total_parameters - sum(param.numel() for param in llm_model.output_layer.parameters())\n",
    "\n",
    "# Print the number of trainable parameters considering weight tying\n",
    "print(f\"Number of trainable parameters considering weight tying: {total_params_excluding_output:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b385bdc2",
   "metadata": {},
   "source": [
    "As we can see, the model is now only 124 million parameters large, matching the original size of the GPT-2 model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28168af2",
   "metadata": {},
   "source": [
    "### GPT ARCHITECTURE PART 7: GENERATING TEXT FROM OUTPUT TOKENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b728e903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_text_generation(model, input_indices, max_tokens, context_window):\n",
    "    # input_indices is (batch, n_tokens) array representing the current context\n",
    "    for _ in range(max_tokens):\n",
    "        \n",
    "        # Truncate the context if it exceeds the supported context window\n",
    "        # E.g., if the LLM supports only 5 tokens, and the context is 10 tokens long,\n",
    "        # only the last 5 tokens are used for prediction\n",
    "        truncated_context = input_indices[:, -context_window:]\n",
    "        \n",
    "        # Get predictions from the model\n",
    "        with torch.no_grad():\n",
    "            output_logits = model(truncated_context)\n",
    "        \n",
    "        # Focus only on the last time step\n",
    "        # (batch, n_tokens, vocab_size)  (batch, vocab_size)\n",
    "        output_logits = output_logits[:, -1, :]  \n",
    "\n",
    "        # Apply softmax to get probabilities\n",
    "        probabilities = torch.softmax(output_logits, dim=-1)  # (batch, vocab_size)\n",
    "\n",
    "        # Get the index of the most probable token\n",
    "        next_token_index = torch.argmax(probabilities, dim=-1, keepdim=True)  # (batch, 1)\n",
    "\n",
    "        # Append the predicted token index to the sequence\n",
    "        input_indices = torch.cat((input_indices, next_token_index), dim=1)  # (batch, n_tokens+1)\n",
    "\n",
    "    return input_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "45a0a8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded: [15496, 11, 314, 716]\n",
      "Encoded tensor shape: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "# Define the starting context\n",
    "initial_text = \"Hello, I am\"\n",
    "\n",
    "# Encode the input text\n",
    "encoded_tokens = text_encoder.encode(initial_text)\n",
    "\n",
    "# Print the encoded token indices\n",
    "print(\"Encoded:\", encoded_tokens)\n",
    "\n",
    "# Convert to a tensor and add a batch dimension\n",
    "encoded_tensor = torch.tensor(encoded_tokens).unsqueeze(0)  # A\n",
    "\n",
    "# Print the shape of the encoded tensor\n",
    "print(\"Encoded tensor shape:\", encoded_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4751aa98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tensor([[15496,    11,   314,   716, 27018, 24086, 47843, 30961, 42348,  7267]])\n",
      "Output length: 10\n"
     ]
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "llm_model.eval()\n",
    "\n",
    "# Generate text using the modified function\n",
    "generated_output = simple_text_generation(\n",
    "    model=llm_model,\n",
    "    input_indices=encoded_tensor,\n",
    "    max_tokens=6,\n",
    "    context_window=LLM_SETTINGS_124M[\"seq_length\"]\n",
    ")\n",
    "\n",
    "# Print the generated output tensor\n",
    "print(\"Output:\", generated_output)\n",
    "\n",
    "# Print the length of the generated sequence\n",
    "print(\"Output length:\", len(generated_output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d3d76d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am Featureiman Byeswickattribute argue\n"
     ]
    }
   ],
   "source": [
    "# Decode the generated token indices back into text\n",
    "decoded_text = text_encoder.decode(generated_output.squeeze(0).tolist())\n",
    "\n",
    "# Print the decoded text\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c3496f",
   "metadata": {},
   "source": [
    "Based on the preceding output you can see that, the model generated outp, which is not at all coherent text. What happened? The reason why the model is unable to produce coherent text is that we haven't trained it yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcc22cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
